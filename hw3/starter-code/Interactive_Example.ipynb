{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this notebook as a sanity check for your implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating search pipelines for two different ranking strategies.\n",
    "\n",
    "* Pipeline 1: Initial ranking by BM25 with re-ranking by LambdaMART (Cross-encoder feature enabled)\n",
    "\n",
    "* Pipeline 2: Initial ranking by Bi-Encoder vector ranker with re-ranking by LambdaMART (Cross-encoder feature enabled)\n",
    "\n",
    "The corpus for the main index is augmented by doc2query queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# your modules are imported here\n",
    "from indexing import Indexer, IndexType, BasicInvertedIndex\n",
    "from document_preprocessor import RegexTokenizer, Doc2QueryAugmenter\n",
    "from ranker import Ranker, BM25, CrossEncoderScorer\n",
    "from vector_ranker import VectorRanker\n",
    "from network_features import NetworkFeatures\n",
    "from l2r import L2RFeatureExtractor, L2RRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change these to point to actual file paths\n",
    "STOPWORD_PATH = '../data/stopwords.txt'\n",
    "DATASET_PATH = '../data/wikipedia_200k_dataset.jsonl'\n",
    "EDGELIST_PATH = '../data/edgelist.csv'\n",
    "NETWORK_STATS_PATH = '../data/network_stats.csv'\n",
    "DOC2QUERY_PATH = '../data/doc2query.csv'\n",
    "MAIN_INDEX = 'main_index_augmented'\n",
    "TITLE_INDEX = 'title_index'\n",
    "RELEVANCE_TRAIN_DATA = '../data/hw2_relevance.train.csv'\n",
    "ENCODED_DOCUMENT_EMBEDDINGS_NPY_DATA = '../data/wiki-200k-vecs.msmarco-MiniLM-L12-cos-v5.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the stopwords\n",
    "\n",
    "stopwords = set()\n",
    "with open(STOPWORD_PATH, 'r', encoding='utf-8') as file:\n",
    "    for stopword in file:\n",
    "        stopwords.add(stopword.strip())\n",
    "f'Stopwords collected {len(stopwords)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of categories for each page (either compute it or load the pre-computed list)\n",
    "docid_to_categories = {}\n",
    "with open(DATASET_PATH, 'rt', encoding='utf-8') as file:\n",
    "    for line in tqdm(file, total=200_000):\n",
    "        document = json.loads(line)\n",
    "        docid_to_categories[document['docid']] = document['categories']\n",
    "f'Document categories collected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or pre-compute the list of categories at least the minimum number of times (specified in the homework)\n",
    "category_counts = Counter()\n",
    "for cats in tqdm(docid_to_categories.values(), total=len(docid_to_categories)):\n",
    "    for c in cats:\n",
    "        category_counts[c] += 1\n",
    "recognized_categories = set(\n",
    "    [cat for cat, count in category_counts.items() if count >= 1000])\n",
    "print(\"saw %d categories\" % len(recognized_categories))\n",
    "\n",
    "# Map each document to the smallert set of categories that occur frequently\n",
    "doc_category_info = {}\n",
    "for docid, cats in tqdm(docid_to_categories.items(), total=len(docid_to_categories)):\n",
    "    valid_cats = [c for c in cats if c in recognized_categories]\n",
    "    doc_category_info[docid] = valid_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_features = {}\n",
    "# Get or load the network statistics for the Wikipedia link network\n",
    "\n",
    "if True:\n",
    "    nf = NetworkFeatures()\n",
    "    print('loading network')\n",
    "    graph = nf.load_network(EDGELIST_PATH, total_edges=92650947)\n",
    "    print('getting stats')\n",
    "    net_feats_df = nf.get_all_network_statistics(graph)\n",
    "    graph = None\n",
    "    print('Saving')\n",
    "    net_feats_df.to_csv(NETWORK_STATS_PATH, index=False)\n",
    "\n",
    "    print(\"converting to dict format\")\n",
    "    network_features = defaultdict(dict)\n",
    "    for i, row in tqdm(net_feats_df.iterrows(), total=len(net_feats_df)):\n",
    "        for col in ['pagerank', 'hub_score', 'authority_score']:\n",
    "            network_features[row['docid']][col] = row[col]\n",
    "    net_feats_df = None\n",
    "else:\n",
    "    with open(NETWORK_STATS_PATH, 'r', encoding='utf-8') as file:\n",
    "        for idx, line in enumerate(file):\n",
    "            if idx == 0:\n",
    "                continue\n",
    "            else:\n",
    "                # the indexes may change depending on your CSV\n",
    "                splits = line.strip().split(',')\n",
    "                network_features[int(splits[0])] = {\n",
    "                    'pagerank': float(splits[1]),\n",
    "                    'authority_score': float(splits[2]),\n",
    "                    'hub_score': float(splits[3])\n",
    "                }\n",
    "f'Network stats collection {len(network_features)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2q = Doc2QueryAugmenter()\n",
    "text = 'The Evil Within is a survival horror video game developed by Tango Gameworks and published by Bethesda Softworks. The game was directed by Resident Evil series creator Shinji Mikami and was released worldwide in October 2014 for PlayStation 3, PlayStation 4, Windows, Xbox 360, and Xbox One.'\n",
    "d2q.get_queries(text, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_augment_dict = defaultdict(lambda: [])\n",
    "with open(DOC2QUERY_PATH, 'r', encoding='utf-8') as file:\n",
    "    dataset = csv.reader(file)\n",
    "    for idx, row in tqdm(enumerate(dataset), total=600_000):\n",
    "        if idx == 0:\n",
    "            continue\n",
    "        doc_augment_dict[int(row[0])].append(row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or build Inverted Indices for the documents' main text and titles\n",
    "#\n",
    "# Estiamted times:\n",
    "#    Document text token counting: 4 minutes\n",
    "#    Document text indexing: 5 minutes\n",
    "#    Title text indexing: 30 seconds\n",
    "preprocessor = RegexTokenizer('\\w+')\n",
    "\n",
    "# Creating and saving the index\n",
    "\n",
    "main_index = Indexer.create_index(\n",
    "        IndexType.InvertedIndex, DATASET_PATH, preprocessor,\n",
    "        stopwords, 50, doc_augment_dict=doc_augment_dict)\n",
    "main_index.save(MAIN_INDEX)\n",
    "\n",
    "title_index = Indexer.create_index(\n",
    "        IndexType.InvertedIndex, DATASET_PATH, preprocessor,\n",
    "        stopwords, 2, text_key='title')\n",
    "title_index.save(TITLE_INDEX)\n",
    "\n",
    "# Loading a preloaded index\n",
    "# main_index = BasicInvertedIndex()\n",
    "# main_index.load(MAIN_INDEX)\n",
    "\n",
    "# title_index = BasicInvertedIndex()\n",
    "# title_index.load(TITLE_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the raw text dictionary by going through the wiki dataset\n",
    "# this dictionary should store only the first 500 characters of the raw documents text\n",
    "\n",
    "raw_text_dict = {}\n",
    "with open(DATASET_PATH, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        raw_text_dict[int(data['docid'])] = data['text'][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the feature extractor. This will be used by both pipelines\n",
    "cescorer = CrossEncoderScorer(raw_text_dict)\n",
    "fe = L2RFeatureExtractor(main_index, title_index, doc_category_info,\n",
    "                         preprocessor, stopwords, recognized_categories,\n",
    "                         network_features, cescorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an intial ranker for determining what to re-rank\n",
    "# Use these with a L2RRanker and then train that L2RRanker model\n",
    "#\n",
    "# Estimated time (using 4 cores via n_jobs): 7 minutes\n",
    "\n",
    "# An initial ranking with BM25 with reranking done by LambdaMART optimizing NDCG\n",
    "bm25 = BM25(main_index)\n",
    "ranker = Ranker(main_index, preprocessor, stopwords, bm25)\n",
    "\n",
    "pipeline_1 = L2RRanker(main_index, title_index, preprocessor,\n",
    "                       stopwords, ranker, fe)\n",
    "\n",
    "pipeline_1.train(RELEVANCE_TRAIN_DATA)\n",
    "\n",
    "# An initial ranking with VectorRanker with reranking done by LambdaMART optimizing NDCG\n",
    "with open(ENCODED_DOCUMENT_EMBEDDINGS_NPY_DATA, 'rb') as file:\n",
    "    encoded_docs = np.load(file)\n",
    "\n",
    "vector_ranker = VectorRanker('sentence-transformers/msmarco-MiniLM-L12-cos-v5',\n",
    "                             encoded_docs, list(main_index.document_metadata.keys()))\n",
    "\n",
    "pipeline_2 = L2RRanker(main_index, title_index, preprocessor,\n",
    "                       stopwords, vector_ranker, fe)\n",
    "\n",
    "pipeline_2.train(RELEVANCE_TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_wiki_title(page_id:int):\n",
    "    url = (\n",
    "        'https://en.wikipedia.org/w/api.php'\n",
    "        '?action=query'\n",
    "        '&prop=info'\n",
    "        '&inprop=subjectid'\n",
    "        f'&pageids={page_id}' \n",
    "        '&format=json')\n",
    "    json_response = requests.get(url).json()\n",
    "    return json_response['query']['pages'][str(page_id)]['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this point, students may have varying answers and observations depending on their implementation and their own features. So, your mileage may vary (YMMV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Query: 'How did the Mongols conquer China?'\n",
    "\n",
    "This query should lead to pages about the different Mongolian invasions of China (there were multiple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(get_wiki_title(doc),score) for doc, score in pipeline_1.query('How did the Mongols conquer China?')[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(get_wiki_title(doc),score) for doc, score in pipeline_2.query('How did the Mongols conquer China?')[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The first result is pretty similar**\n",
    "\n",
    "But the difference is in what lies after maybe the second rank. You would see that the vector ranker would provide better pages overall in the top ranks of the fetched document list (in our experience the vector ranker pipeline focused more on conquests by mongols rather than details about mongols themselves)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of a query where both the pipelines perform badly\n",
    "\n",
    "**top 10 video games** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(get_wiki_title(doc),score) for doc, score in pipeline_1.query('top 10 video games')[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(get_wiki_title(doc),score) for doc, score in pipeline_2.query('top 10 video games')[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results, it doesn't seem that the search engine does very well on this query. Why might that be? Could you think of ways to handle these types of queries? What about other queries where the search engine might just not be very good?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
